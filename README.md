# Tech Challenge Deep Learning - Previs√£o de S√©ries Temporais Financeiras com LSTM

**Tech Challenge 4 - P√≥s Gradua√ß√£o em Machine Learning Engineering**

Aplica√ß√£o produtiva para previs√£o de s√©ries temporais financeiras usando **LSTM (Long Short-Term Memory)** com hiperpar√¢metros otimizados via **Ray Tune**, experimentos rastreados em **MLflow** e API REST servida via **FastAPI**.

---

## üìã Sum√°rio

- [Vis√£o Geral](#vis√£o-geral)
- [Arquitetura do Projeto](#arquitetura-do-projeto)
- [Instala√ß√£o e Setup](#instala√ß√£o-e-setup)
- [Como Executar Localmente](#como-executar-localmente)
- [Scripts de Utilidade](#scripts-de-utilidade)
- [API REST](#api-rest)
- [Conceitos T√©cnicos](#conceitos-t√©cnicos)
- [Modelo Campe√£o](#modelo-campe√£o)
- [Roadmap Futuro](#roadmap-futuro)
- [Contributing](#contributing)

---

## üéØ Vis√£o Geral

Este projeto implementa um **pipeline completo de ML** para previs√£o de pre√ßos de a√ß√µes financeiras usando LSTMs. O fluxo t√≠pico √©:

1. **Prepara√ß√£o de Dados**: Download autom√°tico de dados de a√ß√µes via yfinance
2. **Processamento em Estrat√©gias**: M√∫ltiplas estrat√©gias de processamento de dados (single/multiple tickers)
3. **Otimiza√ß√£o de Hiperpar√¢metros**: Ray Tune executa combina√ß√µes de par√¢metros em paralelo
4. **Rastreamento de Experimentos**: MLflow registra todas as m√©tricas, par√¢metros e artefatos
5. **Sele√ß√£o do Melhor Modelo**: Script autom√°tico identifica o modelo campe√£o
6. **Infer√™ncia**: API REST para fazer previs√µes com o modelo treinado

### Principais Caracter√≠sticas

- ‚úÖ **Arquitetura Modular**: Padr√£o Strategy para flexibilidade de algoritmos
- ‚úÖ **Rastreamento Completo**: MLflow para auditoria e reprodutibilidade
- ‚úÖ **Otimiza√ß√£o Autom√°tica**: Ray Tune para busca de hiperpar√¢metros distribu√≠da
- ‚úÖ **API RESTful**: FastAPI para servir previs√µes em produ√ß√£o
- ‚úÖ **PyTorch Lightning**: Treinamento simplificado e reproduc√≠vel com PyTorch
- ‚úÖ **Monitoramento**: Endpoint para acompanhar lat√™ncia e sa√∫de da infer√™ncia

---

## üèóÔ∏è Arquitetura do Projeto

```
tech-challenge-deep-learning/
‚îÇ
‚îú‚îÄ‚îÄ src/                           # C√≥digo principal
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # FastAPI application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py          # Treinar modelo com config campe√£
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infer.py          # Fazer previs√µes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitor.py        # Status e m√©tricas
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py         # Retornar config carregada
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.py                # Aplica√ß√£o FastAPI principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Processamento de dados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py               # DataPipeline + DataStrategy (abstra√ß√£o)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scaler.py             # TimeSeriesScaler
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # Arquitetura neural
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lstm.py               # LSTM + LSTMFactory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lstm_params.py        # Par√¢metros do modelo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                  # L√≥gica de treinamento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py              # LSTMLightningModule + TrainingStrategy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py            # MAE, RMSE, MAPE
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trainer.py            # TrainerContext (orquestrador)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ inference/                 # Predi√ß√£o em produ√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predictor.py          # Fun√ß√£o predict() principal
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                  # Camada de aplica√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring_service.py # Rastrear lat√™ncia/stats
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                     # Utilit√°rios
‚îÇ       ‚îî‚îÄ‚îÄ model_loader.py       # Carregar config, modelo, scaler
‚îÇ
‚îú‚îÄ‚îÄ scripts/                       # Scripts de execu√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ download_data.py          # Baixa dados de a√ß√µes (yfinance)
‚îÇ   ‚îú‚îÄ‚îÄ run_ray_experiments.py    # Executa Ray Tune com m√∫ltiplas estrat√©gias
‚îÇ   ‚îú‚îÄ‚îÄ champion_selector.py      # Seleciona melhor run, salva best_config.yaml
‚îÇ   ‚îú‚îÄ‚îÄ smoke_train.py            # Teste r√°pido de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ smoke_test_data_pipeline.py # Teste r√°pido de pipeline de dados
‚îÇ
‚îú‚îÄ‚îÄ configs/                       # Configura√ß√µes YAML
‚îÇ   ‚îú‚îÄ‚îÄ best_config.yaml          # ‚≠ê Config do modelo campe√£o (gerado)
‚îÇ   ‚îî‚îÄ‚îÄ ray_experiments.yaml      # Par√¢metros para Ray Tune
‚îÇ
‚îú‚îÄ‚îÄ artifacts/                     # Artefatos de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îî‚îÄ‚îÄ model_final.pt        # ‚≠ê Peso do modelo treinado
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                        # MLflow tracking
‚îÇ   ‚îî‚îÄ‚îÄ [experiment_id]/          # Armazena experimentos e runs
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # Testes automatizados
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îî‚îÄ‚îÄ *.py
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt               # Depend√™ncias Python
‚îú‚îÄ‚îÄ README.md                      # Este arquivo
‚îú‚îÄ‚îÄ CONTRIBUTING.md                # Guia de contribui√ß√£o
‚îî‚îÄ‚îÄ .gitignore
```

### Fluxo de Dados

```
yfinance (dados brutos)
    ‚Üì
DataStrategy (processamento)
    ‚îú‚Üí NoProcessingSingle      (1 ticker, sem engenharia)
    ‚îú‚Üí NoProcessingMultiple    (N tickers, sem engenharia)
    ‚îú‚Üí RangeSingle            (1 ticker + features normalizadas)
    ‚îî‚Üí RangeMultiple           (N tickers + features normalizadas)
    ‚Üì
DataPipeline (batch creation)
    ‚Üì
LSTMLightningModule + PyTorch Lightning Trainer
    ‚Üì
MLflow (log metrics/params/artifacts)
    ‚Üì
model_final.pt + scaler_*.pkl + best_config.yaml
    ‚Üì
API /infer (predi√ß√£o em tempo real)
```

---

## üîß Tecnologias e Justificativas

### **PyTorch Lightning** üî•

**Por que usamos?**

- **Simplicidade**: Reduz 50% do boilerplate de treinamento PyTorch puro
- **Reprodutibilidade**: Gerencia seeds, logging e checkpoints automaticamente
- **Escalabilidade**: Suporta multi-GPU/TPU com uma linha de configura√ß√£o
- **Integra√ß√£o MLflow**: Logger nativo para rastreamento de experimentos

**Exemplo**: Sem Lightning, ter√≠amos ~500 linhas de code para train/val loops. Com Lightning: ~100.

### **Ray Tune** üéØ

**Por que usamos?**

- **Busca Distribu√≠da**: Executa m√∫ltiplas combina√ß√µes de hiperpar√¢metros em paralelo
- **Escalabilidade**: Funciona em cluster com centenas de workers
- **Early Stopping**: Cancela trials ruins automaticamente (Hyperband)
- **Integra√ß√£o MLflow**: Registra cada trial como um run separado

**Exemplo**: 100 combina√ß√µes levaria horas sequencialmente ‚Üí minutos em paralelo.

### **MLflow** üìä

**Por que usamos?**

- **Rastreabilidade**: Cada experimento, run, m√©trica e artefato √© registrado
- **Reprodutibilidade**: Recupera exatamente quais par√¢metros geraram qual resultado
- **Sele√ß√£o Autom√°tica**: `champion_selector.py` encontra o melhor run facilmente
- **UI Web**: Visualiza experimentos via `mlflow ui`

**Exemplo**: Sem MLflow, cada treinamento seria "uma caixa preta". Com MLflow, sabemos:
- Quais par√¢metros usamos
- Quais m√©tricas obtivemos
- Onde est√£o os artefatos (modelo, scaler)

---

## üì¶ Instala√ß√£o e Setup

### Requisitos

- **Python >= 3.13**
- `pip` e `venv` instalados

### Setup Local

```bash
# Clone o reposit√≥rio
git clone <repo-url>
cd tech-challenge-deep-learning

# Crie ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Instale depend√™ncias
pip install -r requirements.txt

# Valide a instala√ß√£o (rodando testes)
pytest -q
```

### Depend√™ncias Principais

```
torch>=2.0.0             # Deep learning framework
pytorch-lightning>=2.0   # Treinamento simplificado
mlflow>=2.0              # Tracking de experimentos
ray[tune]>=2.0           # Otimiza√ß√£o de hiperpar√¢metros
fastapi>=0.100           # API REST
uvicorn>=0.23            # ASGI server
pandas>=2.0              # Manipula√ß√£o de dados
yfinance>=0.2.30         # Download de dados financeiros
scikit-learn>=1.3        # Utilities (scalers, metrics)
```

Ver [requirements.txt](requirements.txt) para lista completa.

---

## üöÄ Como Executar Localmente

### 1Ô∏è‚É£ Baixar Dados (Opcional)

Se n√£o houver dados em `data/raw/AAPL.csv`:

```bash
python -m scripts.download_data
```

### 2Ô∏è‚É£ Executar Ray Tune para Otimizar Hiperpar√¢metros

Executa todas as combina√ß√µes de estrat√©gias e par√¢metros em paralelo:

```bash
python -m scripts.run_ray_experiments
```

**Sa√≠da esperada:**
- M√∫ltiplos runs registrados em MLflow
- Artefatos salvos em `mlruns/`
- Hist√≥rico de experimentos consult√°vel via `mlflow ui`

### 3Ô∏è‚É£ Selecionar Modelo Campe√£o

Identifica o melhor run e salva configura√ß√£o:

```bash
python -m scripts.champion_selector
```

**Sa√≠da esperada:**
- `configs/best_config.yaml` criado
- Melhor run ID exibido no console
- M√©tricas do campe√£o mostradas

### 4Ô∏è‚É£ Iniciar API REST

```bash
# Desenvolvimento com reload autom√°tico
uvicorn src.api.app:app --reload --host 0.0.0.0 --port 8000
```

**Sa√≠da esperada:**
```
INFO:     Uvicorn running on http://0.0.0.0:8000
INFO:     Application startup complete
```

Acesse a documenta√ß√£o interativa: **http://localhost:8000/docs**

### 5Ô∏è‚É£ (Opcional) Visualizar Experimentos MLflow

Em outro terminal:

```bash
mlflow server --backend-store-uri file:./mlruns --host 127.0.0.1 --port 5000
```

Acesse: **http://127.0.0.1:5000**

---

## üìù Scripts de Utilidade

### `download_data.py`

**Responsabilidade**: Baixar dados hist√≥ricos de a√ß√µes

```bash
python -m scripts.download_data
```

**O que faz**:
- Download via yfinance para ticker especificado (padr√£o: AAPL)
- Salva CSV em `data/raw/{TICKER}.csv`
- Valida colunas obrigat√≥rias (High, Low, Close, Volume)
- Implementa cache local (n√£o faz download repetido)

**Exemplo de uso em c√≥digo**:
```python
from scripts.download_data import download
download(ticker="AAPL", start="2020-01-01")
```

---

### `run_ray_experiments.py`

**Responsabilidade**: Executar combina√ß√µes de hiperpar√¢metros com Ray Tune

```bash
python -m scripts.run_ray_experiments
```

**O que faz**:
1. L√™ `configs/ray_experiments.yaml`
2. Cria produto cartesiano de todos os par√¢metros
3. Para cada combina√ß√£o:
   - Instancia uma estrat√©gia de treinamento (NoProcessingSingle, etc.)
   - Cria DataPipeline correspondente
   - Executa treinamento via PyTorch Lightning
   - Loga m√©tricas em MLflow
4. Retorna hist√≥rico de todos os runs

**Estrat√©gias Testadas**:
- `NoProcessingSingleStrategy`: 1 ticker, sem engenharia de features
- `NoProcessingMultipleStrategy`: N tickers, sem engenharia
- `RangeSingleStrategy`: 1 ticker com normaliza√ß√£o de features
- `RangeMultipleStrategy`: N tickers com normaliza√ß√£o

**Exemplo de sa√≠da**:
```
Trial 1/100: NoProcessingSingleStrategy
  ‚îú‚îÄ val_rmse: 2.34
  ‚îú‚îÄ val_mae: 1.89
  ‚îî‚îÄ Run ID: abc123def456

Trial 2/100: NoProcessingMultipleStrategy
  ‚îú‚îÄ val_rmse: 2.12 ‚úì (melhor at√© agora)
  ‚îú‚îÄ val_mae: 1.72
  ‚îî‚îÄ Run ID: xyz789uvw012

...
```

---

### `champion_selector.py`

**Responsabilidade**: Selecionar o melhor modelo e salvar sua configura√ß√£o

```bash
python -m scripts.champion_selector
```

**O que faz**:
1. Query MLflow por todos os runs do experimento
2. Ordena por `val_rmse` (menor √© melhor)
3. Extrai par√¢metros do melhor run
4. Reconstr√≥i configura√ß√£o sem√¢ntica
5. Salva em `configs/best_config.yaml`

**Estrutura do best_config.yaml**:
```yaml
metadata:
  selected_on: "2024-01-09 14:30:45"
  experiment_name: "lstm_strategy_experiments"
  run_id: "abc123..."
  metric: "val_rmse"
  metric_value: 2.12
  strategy: "NoProcessingMultipleStrategy"

model:
  type: "LSTM"
  input_size: 4
  hidden_size: 128
  num_layers: 2
  dropout: 0.2
  output_size: 1
  layer_config: ["LSTM", "Linear"]

training:
  learning_rate: 0.001
  batch_size: 32
  num_epochs: 50
  shuffle: true

data:
  tickers: ["AAPL", "MSFT"]
  period: "1y"
  seq_len: 20
  train_ratio: 0.7
  val_ratio: 0.15
  scaler: "TimeSeriesScaler"
```

---

### `smoke_train.py` e `smoke_test_data_pipeline.py`

**Responsabilidade**: Testes r√°pidos para valida√ß√£o

**smoke_train.py**:
- Treina modelo com configura√ß√£o m√≠nima em ~30 segundos
- Valida pipeline completo de treinamento
- N√£o registra em MLflow

**smoke_test_data_pipeline.py**:
- Testa carregamento e processamento de dados
- Valida formato de tensores
- Detecta problemas em etapa inicial

**Uso**:
```bash
pytest tests/               # Testes completos
python -m scripts.smoke_train
python -m scripts.smoke_test_data_pipeline
```

---

## üîå API REST

A API √© servida via **FastAPI** e documentada automaticamente via **Swagger**.

### Iniciar Servidor

```bash
uvicorn src.api.app:app --reload --host 0.0.0.0 --port 8000
```

### Endpoints

#### **[GET] `/`**

Retorna informa√ß√µes gerais da API.

**Exemplo de Resposta**:
```json
{
  "title": "ML Training API",
  "description": "API for training LSTM models",
  "version": "1.0.0"
}
```

---

#### **[POST] `/train/`**

Treina modelo usando configura√ß√£o do modelo campe√£o (`best_config.yaml`).

**Pr√©-requisito**: `champion_selector.py` deve ter sido executado.

**Payload**: Nenhum (usa configura√ß√£o salva)

**Exemplo de Requisi√ß√£o**:
```bash
curl -X POST http://localhost:8000/train/
```

**Exemplo de Resposta** (ap√≥s conclus√£o):
```json
{
  "status": "success",
  "message": "Training completed",
  "metrics": {
    "final_train_loss": 0.0234,
    "final_val_loss": 0.0456,
    "val_rmse": 2.34,
    "val_mae": 1.89
  },
  "model_path": "artifacts/models/model_final.pt",
  "training_duration_seconds": 245.67
}
```

**Poss√≠veis Erros**:
- `404`: best_config.yaml n√£o encontrado
- `400`: Par√¢metros inv√°lidos
- `500`: Erro durante treinamento

---

#### **[POST] `/infer/`**

Faz previs√£o com modelo treinado.

**Payload**:
```json
{
  "sequence": [[1.2, 2.3, 3.4, 4.5], [1.5, 2.6, 3.7, 4.8], ...]
}
```

Aceita dois formatos:
- **Multivariado** (recomendado): `[[f1,f2,f3,f4], ...]` - lista de timesteps com N features
- **Univariado**: `[1.2, 3.4, 5.6, ...]` - pre√ßo de fechamento apenas

**Exemplo de Requisi√ß√£o** (curl):
```bash
curl -X POST http://localhost:8000/infer/ \
  -H "Content-Type: application/json" \
  -d '{
    "sequence": [
      [150.23, 152.10, 149.50, 1000000],
      [151.45, 153.20, 150.80, 1200000],
      [152.67, 154.40, 152.00, 950000]
    ]
  }'
```

**Exemplo de Resposta**:
```json
{
  "prediction": 153.45,
  "timestamp": "2024-01-09T14:45:30.123456",
  "latency_ms": 12.34
}
```

**Poss√≠veis Erros**:
- `404`: Modelo ou scaler n√£o encontrado
- `400`: Sequ√™ncia inv√°lida (dimens√µes incompat√≠veis)
- `500`: Erro durante infer√™ncia

---

#### **[GET] `/monitor/`**

Retorna m√©tricas de sa√∫de e monitoramento da API.

**Exemplo de Resposta**:
```json
{
  "status": "healthy",
  "total_inferences": 1250,
  "avg_latency_ms": 11.23,
  "min_latency_ms": 5.45,
  "max_latency_ms": 28.90,
  "last_inference_timestamp": "2024-01-09T14:50:15.654321"
}
```

---

#### **[GET] `/config/`**

Retorna a configura√ß√£o do modelo campe√£o carregada em mem√≥ria.

**Exemplo de Resposta**:
```json
{
  "metadata": {
    "selected_on": "2024-01-09 14:30:45",
    "experiment_name": "lstm_strategy_experiments",
    "run_id": "abc123...",
    "metric": "val_rmse",
    "metric_value": 2.12,
    "strategy": "NoProcessingMultipleStrategy"
  },
  "model": {
    "type": "LSTM",
    "input_size": 4,
    "hidden_size": 128,
    "num_layers": 2,
    "dropout": 0.2,
    "output_size": 1,
    "layer_config": ["LSTM", "Linear"]
  },
  "training": {
    "learning_rate": 0.001,
    "batch_size": 32,
    "num_epochs": 50,
    "shuffle": true
  },
  "data": {
    "tickers": ["AAPL", "MSFT"],
    "period": "1y",
    "seq_len": 20,
    "train_ratio": 0.7,
    "val_ratio": 0.15,
    "scaler": "TimeSeriesScaler"
  }
}
```

---

### Teste R√°pido dos Endpoints

```bash
# 1. Iniciar servidor em um terminal
uvicorn src.api.app:app --reload

# 2. Em outro terminal, testar endpoints
# Obter configura√ß√£o
curl http://localhost:8000/config/ | python -m json.tool

# Fazer previs√£o
curl -X POST http://localhost:8000/infer/ \
  -H "Content-Type: application/json" \
  -d '{"sequence": [[150, 152, 149, 1000000], [151, 153, 150, 1200000]]}'

# Verificar sa√∫de
curl http://localhost:8000/monitor/ | python -m json.tool
```

---

## üìä Conceitos T√©cnicos

### DataPipeline e Padr√£o Strategy

O projeto utiliza o **padr√£o Strategy** para flexibilizar o processamento de dados:

#### **DataStrategy** (Interface Abstrata)

```
DataStrategy (ABC)
  ‚îú‚îÄ NoProcessingSingle   ‚Üí 1 ticker, sem engenharia
  ‚îú‚îÄ NoProcessingMultiple ‚Üí N tickers, sem engenharia
  ‚îú‚îÄ RangeSingle          ‚Üí 1 ticker + normaliza√ß√£o Range
  ‚îî‚îÄ RangeMultiple        ‚Üí N tickers + normaliza√ß√£o Range
```

**Responsabilidades**:
1. Carregar dados hist√≥ricos de a√ß√µes
2. Validar colunas e tipos
3. Criar sequ√™ncias temporais (sliding window)
4. Normalizar features (se aplic√°vel)

**Exemplo**:
```python
from src.data.data import NoProcessingSingleStrategy
from src.data.scaler import TimeSeriesScaler

strategy = NoProcessingSingleStrategy()
X, y = strategy.process(
    tickers=["AAPL"],
    period="1y",
    seq_len=20
)
# X.shape = (samples, 20, 4)  # 4 features: High, Low, Close, Volume
# y.shape = (samples, 1)       # Target (pre√ßo de fechamento)
```

#### **DataPipeline** (Orchestrator)

Orquestra a estrat√©gia escolhida e cria **DataLoaders**:

```python
from src.data.data import DataPipeline

pipeline = DataPipeline(
    strategy=NoProcessingSingleStrategy(),
    batch_size=32,
    shuffle=True,
    scaler=TimeSeriesScaler()
)

train_loader, val_loader, test_loader = pipeline.create_dataloaders()

for X_batch, y_batch in train_loader:
    # X_batch.shape = (32, 20, 4)
    # y_batch.shape = (32, 1)
    pass
```

---

### TrainerStrategy e TrainerContext

Padr√£o Strategy para orquestra√ß√£o de treinamento:

#### **TrainingStrategy** (Interface Abstrata)

Define QUAL pipeline, QUAL modelo e QUAIS hiperpar√¢metros usar:

```python
class TrainingStrategy(ABC):
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Identificador √∫nico da estrat√©gia"""
    
    @abstractmethod
    def get_data_pipeline(self) -> DataPipeline:
        """Retorna pipeline configurado"""
    
    @abstractmethod
    def get_model_factory(self, input_size: int) -> LSTMFactory:
        """Retorna factory com arquitetura configurada"""
    
    @abstractmethod
    def get_training_params(self) -> Dict[str, Any]:
        """Retorna hiperpar√¢metros de treinamento"""
```

**Estrat√©gias Implementadas**:
- `NoProcessingSingleStrategy`: 1 ticker, dados brutos
- `NoProcessingMultipleStrategy`: N tickers, dados brutos
- `RangeSingleStrategy`: 1 ticker com normaliza√ß√£o Range
- `RangeMultipleStrategy`: N tickers com normaliza√ß√£o Range

#### **TrainerContext** (Executor)

Orquestra o treinamento:

```python
from src.training.trainer import TrainerContext

strategy = NoProcessingSingleStrategy(training_params)
trainer = TrainerContext(strategy)
metrics = trainer.train()

# Internamente:
# 1. Obt√©m pipeline da estrat√©gia
# 2. Obt√©m model factory da estrat√©gia
# 3. Cria LSTMLightningModule
# 4. Executa treinamento via PyTorch Lightning
# 5. Loga em MLflow
# 6. Salva modelo e artefatos
```

---

### Modelo LSTM e Factory

#### **LSTMFactory**

Cria arquiteturas LSTM flex√≠veis dado um `layer_config`:

```python
from src.models.lstm import LSTMFactory
from src.models.lstm_params import LSTMParams

params = LSTMParams(
    input_size=4,
    hidden_size=128,
    num_layers=2,
    dropout=0.2,
    output_size=1
)

layer_config = ["LSTM", "Linear"]  # Sequ√™ncia de camadas

factory = LSTMFactory(layer_config, params)
model = factory.create()

# Produz:
# LSTM(4 ‚Üí 128, num_layers=2, dropout=0.2)
#   ‚Üì
# Linear(128 ‚Üí 1)
```

**Camadas Suportadas**:
- `LSTM`: Long Short-Term Memory
- `Linear`: Fully connected
- `ReLU`, `Tanh`, `Sigmoid`: Activation functions
- `Flatten`: Flatten tensor

---

### Normaliza√ß√£o com TimeSeriesScaler

Scaler baseado em `StandardScaler` do scikit-learn, mant√©m hist√≥rico de fit:

```python
from src.data.scaler import TimeSeriesScaler

scaler = TimeSeriesScaler()

# Fit com dados de treino
train_data = ...  # shape: (n_samples, n_features)
scaler.fit(train_data)

# Transform dados
train_scaled = scaler.transform(train_data)

# Transform dados novos
new_data = ...
new_scaled = scaler.transform(new_data)

# Inverse transform
original = scaler.inverse_transform(new_scaled)
```

---

## ‚≠ê Modelo Campe√£o

### Como √© Definido

1. **Execu√ß√£o**: `run_ray_experiments.py` testa m√∫ltiplas estrat√©gias e hiperpar√¢metros
2. **Rastreamento**: MLflow registra cada run com m√©tricas (val_rmse, val_mae, val_mape)
3. **Sele√ß√£o**: `champion_selector.py` ordena por `val_rmse` e seleciona o menor
4. **Persist√™ncia**: Configura√ß√£o √© salva em `configs/best_config.yaml`

### Artefatos do Campe√£o

```
artifacts/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ model_final.pt           # Pesos do modelo (torch.save)
‚îú‚îÄ‚îÄ scalers/
‚îÇ   ‚îî‚îÄ‚îÄ scaler_final.pkl         # Scaler fitted (joblib.dump)
configs/
‚îî‚îÄ‚îÄ best_config.yaml             # Par√¢metros e metadados
```

### Como √© Utilizado

1. **API /train/**: Carrega `best_config.yaml` e treina modelo com esses par√¢metros
2. **API /infer/**: Carrega modelo_final.pt e scaler_final.pkl para fazer predi√ß√µes
3. **Reprodutibilidade**: Qualquer pessoa pode recriar exatamente o mesmo modelo

---

## üóìÔ∏è Roadmap Futuro

### üîÑ Implementa√ß√£o Futura - Endpoint de Update

Adicionar endpoint para retrainer o modelo campe√£o com dados novos:

```python
# [POST] /train/update
# Desci√ß√£o: Retrena modelo campe√£o com dados novos (sem busca de hiperpar√¢metros)

@router.post("/update")
def update_champion_model(request: UpdateRequest):
    """
    Retreina o modelo campe√£o com novos dados.
    
    Payload:
    {
        "period": "30d",  # Novo per√≠odo
        "force_download": true  # For√ßar download dos dados
    }
    
    Resposta:
    {
        "status": "success",
        "message": "Model updated with new data",
        "metrics": {...},
        "timestamp": "2024-01-09T..."
    }
    """
```

## üìñ Contributing

Para contribuir, consulte [CONTRIBUTING.md](CONTRIBUTING.md).

**Resumo r√°pido**:

1. Clone o reposit√≥rio
2. Crie uma branch (`git checkout -b feature/minha-feature`)
3. C√≥digo + testes (`pytest`)
4. Formata√ß√£o (`black .`)
5. Lint (`pylint src || true`)
6. Push e abra Pull Request

**Requisitos**:
- Python >= 3.13
- Cobertura de testes (happy path + 1 edge case m√≠nimo)
- Black formatting
- Sem falhas cr√≠ticas do Pylint

---

## üìö Estrutura de Tipos

O projeto usa **dataclasses** para type safety:

```python
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class TrainingParams:
    tickers: List[str]
    period: Optional[str]
    seq_len: int
    num_epochs: int
    learning_rate: float
    batch_size: int
    layer_config: dict
    lstm_params: dict
    # ... mais par√¢metros
```

---

## üß™ Testes

Executar testes:

```bash
# Todos os testes
pytest -v

# Apenas teste do data pipeline
pytest -v src/data/tests/

# Com cobertura
pytest --cov=src

# Teste r√°pido para validar setup
python -m scripts.smoke_train
```

---

## üîç Monitoramento

### MLflow UI

```bash
mlflow server --backend-store-uri file:./mlruns --host 127.0.0.1 --port 5000
```

Acesse: **http://127.0.0.1:5000**

Visualize:
- Todos os experimentos executados
- M√©tricas de cada run
- Compara√ß√£o de par√¢metros
- Artefatos salvos

---

## üìã Exemplo Completo de Workflow

```bash
# 1. Setup
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Baixar dados (se necess√°rio)
python -m scripts.download_data

# 3. Rodar testes r√°pidos
python -m scripts.smoke_test_data_pipeline
python -m scripts.smoke_train

# 4. Otimizar hiperpar√¢metros
python -m scripts.run_ray_experiments
# ‚è≥ Aguarde conclus√£o (pode levar horas dependendo do dataset)

# 5. Selecionar modelo campe√£o
python -m scripts.champion_selector

# 6. Iniciar API
uvicorn src.api.app:app --reload

# 7. (Novo terminal) Visualizar experimentos
mlflow server --backend-store-uri file:./mlruns --host 127.0.0.1 --port 5000

# 8. Fazer previs√µes via API
curl -X POST http://localhost:8000/infer/ \
  -H "Content-Type: application/json" \
  -d '{"sequence": [[150, 152, 149, 1000000], [151, 153, 150, 1200000]]}'
```

---

## üìù Licen√ßa

Projeto desenvolvido para **Tech Challenge 4** da P√≥s Gradua√ß√£o em Machine Learning Engineering.

---

## üìû Suporte

Para d√∫vidas ou issues, abra uma issue no reposit√≥rio ou consulte [CONTRIBUTING.md](CONTRIBUTING.md).